# Default configuration for AI Co-Scientist

system:
  debug: true
  log_level: "DEBUG"
  max_iterations: 5
  tournament_size: 8
  top_hypotheses_count: 3

# Model configuration
models:
  default_provider: "azure_openai"  # Changed from "openai" to "azure_openai"
  
  # Azure OpenAI configuration
  azure_openai:
    deployment_id: "co-scientist-gpt-4o-mini"  # Your Azure OpenAI deployment ID for completions
    embedding_deployment: "text-embedding-ada-002"  # Your Azure OpenAI deployment ID for embeddings
    # The following values are loaded from environment variables:
    # api_key: From AZURE_OPENAI_API_KEY
    # api_version: From AZURE_OPENAI_API_VERSION
    # endpoint: From AZURE_OPENAI_ENDPOINT
    max_tokens: 4096
    temperature: 0.7
    timeout: 60  # Timeout in seconds
  
  openai:
    model_name: "gpt-4o"
    api_key: ""  # Set via environment variable OPENAI_API_KEY
    max_tokens: 4096
    temperature: 0.7
  
  anthropic:
    model_name: "claude-3-opus-20240229"
    api_key: ""  # Set via environment variable ANTHROPIC_API_KEY
    max_tokens: 4096
    temperature: 0.7
  
  google:
    model_name: "gemini-pro"
    api_key: ""  # Set via environment variable GOOGLE_API_KEY
    max_tokens: 8192
    temperature: 0.7
  
  huggingface:
    model_name: "mistralai/Mistral-7B-Instruct-v0.2"
    api_key: ""  # Set via environment variable HF_API_KEY
    max_tokens: 2048
    temperature: 0.7
  
  local:
    model_path: "models/local_model"
    device: "cuda"  # or "cpu"
    max_tokens: 2048
    temperature: 0.7
    
  ollama:
    model_name: "llama3"  # Default model, users can change to any model available in their Ollama instance
    api_base: "http://localhost:11434"  # Default Ollama API endpoint
    max_tokens: 2048
    temperature: 0.7
    timeout: 120  # Timeout in seconds

# Agent configuration - now using "default" which will resolve to azure_openai
agents:
  # Generation agent config as described in the paper
  generation:
    count: 2  # Number of parallel generation agents
    prompt_template: "templates/generation_agent.txt"
    model_provider: "default"  # Will use azure_openai
    temperature: 0.8  # Override default temperature
    generation_count: 5
    strategies:
      - literature_exploration
      - scientific_debate
      - assumptions_identification
      - research_expansion
  
  # Reflection agent config as described in the paper
  reflection:
    count: 2  # Number of parallel reflection agents
    prompt_template: "templates/reflection_agent.txt"
    model_provider: "default"
    detail_level: comprehensive
    review_types:
      - initial_review
      - full_review
      - deep_verification
      - observation_review
      - simulation_review
  
  # Ranking agent config with Elo tournament as described in the paper
  ranking:
    count: 1
    prompt_template: "templates/ranking_agent.txt"
    model_provider: "default"
    tournament_size: 8
    elo_k_factor: 32
    initial_elo: 1200
    debate_turns: 3
    full_debate_threshold: 0.25 # Top % for full debates
    criteria:
      novelty: 0.25
      plausibility: 0.25
      testability: 0.25
      impact: 0.25
  
  # Evolution agent with multiple strategies as described in the paper
  evolution:
    count: 2  # Increased for more parallel evolution
    prompt_template: "templates/evolution_agent.txt"
    model_provider: "default"
    creativity_level: 0.7
    evolution_count: 3
    evolution_strategies:
      - enhance_grounding
      - improve_coherence
      - improve_practicality  
      - improve_feasibility
      - inspire
      - combine
      - simplify
      - out_of_box
    strategies_weights:
      enhance_grounding: 0.2
      improve_coherence: 0.15
      improve_practicality: 0.15
      improve_feasibility: 0.15
      inspire: 0.1
      combine: 0.1
      simplify: 0.05
      out_of_box: 0.1
  
  # Proximity agent for calculating hypothesis similarity
  proximity:
    count: 1
    prompt_template: "templates/proximity_agent.txt"
    model_provider: "default"
    search_depth: comprehensive
    similarity_threshold: 0.7
    clustering_method: hierarchical
  
  # Meta-review agent for research overview and contact identification
  meta_review:
    count: 1
    prompt_template: "templates/meta_review_agent.txt"
    model_provider: "default"
    output_format: comprehensive
    research_overview_style: detailed
    citation_style: apa
    contact_identification: true

# Task execution configuration
execution:
  queue_backend: "redis"  # Options: redis, rabbitmq
  redis:
    host: "localhost"
    port: 6379
    db: 0
  rabbitmq:
    host: "localhost"
    port: 5672
    user: "guest"
    password: "guest"
  timeout: 300  # seconds
  retry_limit: 3
  parallel_tasks: 4

# Memory configuration
memory:
  backend: "file_system"  # Options: mongodb, file_system, in_memory
  mongodb:
    uri: "mongodb://localhost:27017/"
    db_name: "co_scientist"
  retention_period: 30  # days

# Tool configuration
tools:
  web_search:
    enabled: true
    provider: "google"  # Options: google, bing, ddg
    api_key: ""  # Set via environment variable SEARCH_API_KEY
    max_results: 5
  
  alphafold:
    enabled: false
    api_endpoint: "https://alphafold.example.com/api"
    api_key: ""  # Set via environment variable ALPHAFOLD_API_KEY
  
  pubmed:
    enabled: true
    email: "user@example.com"  # Required for PubMed API
    max_results: 10
  
  custom_tool_template:
    enabled: false
    api_endpoint: ""
    api_key: ""

# UI configuration
ui:
  api_port: 8000
  cors_origins: ["http://localhost:3000"]
  auth_enabled: false
  
# Scientific workflow configuration
workflow:
  max_iterations: 5
  top_hypotheses_count: 5
  tournament_matches_per_iteration: 10
  debate_threshold: 0.25 # Top % of hypotheses for full debates
  phases:
    - generation
    - reflection
    - ranking
    - evolution
    - meta_review
  phase_weights:
    generation: 0.25
    reflection: 0.2
    ranking: 0.15
    evolution: 0.3
    meta_review: 0.1 